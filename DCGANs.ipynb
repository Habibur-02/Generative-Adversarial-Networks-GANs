{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "DCGANs",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibur-02/Generative-Adversarial-Networks-GANs/blob/main/DCGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "pThkeCFZItGL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCGAN= Deep Convolution GANs\n",
        "Upsampling convolution\n",
        "It is also called often.\n",
        "`Deconvolution or\n",
        "Fractionally strided convolution or\n",
        "Upconvolution`"
      ],
      "metadata": {
        "id": "MFUT52oJItGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Size= (I-1)*S-2P+K\n",
        "I=Input size\n",
        "S=Stride\n",
        "P=Padding\n",
        "K=Kernel\n"
      ],
      "metadata": {
        "id": "IeySup6TItGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input=torch.randn(1,1,6,6)\n",
        "input\n",
        "\n",
        "model=nn.Sequential(\n",
        "    nn.Conv2d(in_channels=1,\n",
        "             out_channels=10,\n",
        "             kernel_size=2,\n",
        "             padding=1,\n",
        "             stride=1,\n",
        "             bias=True),\n",
        "    nn.LeakyReLU(0.3),\n",
        "    nn.BatchNorm2d(10),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Tanh()\n",
        "\n",
        ")\n",
        "\n",
        "output=model(input)\n",
        "output.shape\n",
        "# output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:57:42.454375Z",
          "iopub.execute_input": "2025-08-07T19:57:42.454799Z",
          "iopub.status.idle": "2025-08-07T19:57:42.465928Z",
          "shell.execute_reply.started": "2025-08-07T19:57:42.454765Z",
          "shell.execute_reply": "2025-08-07T19:57:42.464997Z"
        },
        "id": "7_hcS8XyItGV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input= torch.randn(1,3,8,8)\n",
        "input\n",
        "\n",
        "model=nn.Sequential(\n",
        "    nn.ConvTranspose2d(\n",
        "        in_channels=3,\n",
        "        out_channels=1,\n",
        "        kernel_size=2,\n",
        "             padding=1,\n",
        "             stride=1,\n",
        "             bias=True\n",
        "\n",
        "    ),\n",
        "    nn.LeakyReLU(0.3),\n",
        "    nn.BatchNorm2d(1),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "output=model(input)\n",
        "output.shape\n",
        "\n",
        "output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:57:46.493056Z",
          "iopub.execute_input": "2025-08-07T19:57:46.493887Z",
          "iopub.status.idle": "2025-08-07T19:57:46.505496Z",
          "shell.execute_reply.started": "2025-08-07T19:57:46.493855Z",
          "shell.execute_reply": "2025-08-07T19:57:46.504674Z"
        },
        "id": "k4eIgOB3ItGX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# f(x)=x if x≥0\n",
        "#      αx if x<0"
      ],
      "metadata": {
        "id": "4SisdKmgItGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "latent_dim = 100\n",
        "img_size = 32\n",
        "channels = 3\n",
        "batch_size = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 1\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "os.makedirs(\"dcgan_cifar10_output\", exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  # Pixel: [-1, 1]\n",
        "])\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.CIFAR10(root=\"./data\", download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:57:50.615229Z",
          "iopub.execute_input": "2025-08-07T19:57:50.615519Z",
          "iopub.status.idle": "2025-08-07T19:57:51.953663Z",
          "shell.execute_reply.started": "2025-08-07T19:57:50.615498Z",
          "shell.execute_reply": "2025-08-07T19:57:51.952428Z"
        },
        "id": "MuPN7vvZItGa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "latent_dim = 100\n",
        "img_channels = 3\n",
        "img_size = 32\n",
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(\"dcgan_outputs\", exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:57:56.687949Z",
          "iopub.execute_input": "2025-08-07T19:57:56.688301Z",
          "iopub.status.idle": "2025-08-07T19:57:57.925221Z",
          "shell.execute_reply.started": "2025-08-07T19:57:56.688278Z",
          "shell.execute_reply": "2025-08-07T19:57:57.924211Z"
        },
        "id": "C0Ng9GmUItGb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model=nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0), #in_chan,out_chan, kernel, stride, padd\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2,1), #in_chan,out_chan, kernel, stride, padd\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),       # (B,128,16,16)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, img_channels, 4, 2, 1),# (B,3,32,32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self,z):\n",
        "        return self.model(z)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model= nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 128, 4,2,1), #[B,128, 16, 16]\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128,256,4,2,1),   #8*8\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),  #4*4\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512,1,4,1,0),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "\n",
        "        )\n",
        "    def forward(self, img):\n",
        "        out=self.model(img)\n",
        "        return out.view(-1,1)\n",
        "\n",
        "\n",
        "model_Gen= Generator().to(device)\n",
        "model_Gen\n",
        "\n",
        "model_Dis=Discriminator().to(device)\n",
        "\n",
        "model_Dis\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:58:03.109216Z",
          "iopub.execute_input": "2025-08-07T19:58:03.109514Z",
          "iopub.status.idle": "2025-08-07T19:58:03.1746Z",
          "shell.execute_reply.started": "2025-08-07T19:58:03.109493Z",
          "shell.execute_reply": "2025-08-07T19:58:03.173795Z"
        },
        "id": "oRk5CfNJItGb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.BCELoss()\n",
        "\n",
        "optimizer_G=torch.optim.Adam(params=model_Gen.parameters(),lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D=torch.optim.Adam(params=model_Dis.parameters(),lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "\n",
        "fixed_noise=torch.randn(64, latent_dim, 1, 1, device=device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:58:09.656095Z",
          "iopub.execute_input": "2025-08-07T19:58:09.656437Z",
          "iopub.status.idle": "2025-08-07T19:58:09.663644Z",
          "shell.execute_reply.started": "2025-08-07T19:58:09.656414Z",
          "shell.execute_reply": "2025-08-07T19:58:09.662867Z"
        },
        "id": "VoPWDf_DItGd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (imgs, _) in enumerate(train_loader):\n",
        "    if i>1:\n",
        "        break\n",
        "    imgs=imgs.to(device)\n",
        "    batch=imgs.size(0)\n",
        "    real_label=torch.full((batch, 1), 0.9, device=device)\n",
        "    fake_label=torch.zeros(batch, 1).to(device)\n",
        "    # real_out=model_Dis()\n",
        "    print(imgs.shape)\n",
        "    #trainging discriminator\n",
        "    optimizer_D.zero_grad()\n",
        "    z=torch.randn(batch, latent_dim, 1, 1, device=device)\n",
        "    real_out=model_Dis(imgs)\n",
        "    real_loss=loss_fn(real_out, real_label)\n",
        "\n",
        "    fake_imgs=model_Gen(z)\n",
        "    fake_out=model_Dis(fake_imgs.detach())\n",
        "    fake_loss=loss_fn(fake_out, fake_label)\n",
        "\n",
        "    total_loss=real_loss+fake_loss\n",
        "    print(total_loss.item())\n",
        "    total_loss.backward()\n",
        "    optimizer_D.step()\n",
        "    #Generator training\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "\n",
        "    gen_img=model_Gen(z)\n",
        "    dis_out_val=model_Dis(gen_img)\n",
        "\n",
        "    gen_loss=loss_fn(dis_out_val,real_label)\n",
        "    print(gen_loss.item())\n",
        "    gen_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "\n",
        "    if i%1==0:\n",
        "        print(f\"i->{i} D[{total_loss.item()}] G[{gen_loss.item()}]\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_imgs=model_Gen(fixed_noise).detach().cpu()\n",
        "        save_image(fake_sample, f\"dcgan_outputs/fake_{epoch:03d}_{k:04d}.png\", normalize=True)\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model_Gen.state_dict(),\"dcgan_generate.pth\")\n",
        "torch.save(model_Dis.state_dict(),\"dcgan_discriminator.pth\")\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:58:13.976545Z",
          "iopub.execute_input": "2025-08-07T19:58:13.976878Z",
          "iopub.status.idle": "2025-08-07T19:58:20.718917Z",
          "shell.execute_reply.started": "2025-08-07T19:58:13.976854Z",
          "shell.execute_reply": "2025-08-07T19:58:20.718003Z"
        },
        "id": "M20ixslZItGe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "# ========== Hyperparameters ==========\n",
        "latent_dim = 100\n",
        "img_channels = 3\n",
        "img_size = 32\n",
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "epochs = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(\"dcgan_outputs\", exist_ok=True)\n",
        "\n",
        "# ========== DataLoader ==========\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ========== Generator ==========\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, img_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "# ========== Discriminator ==========\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 128, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        return out.view(-1, 1)\n",
        "\n",
        "# ========== Model Initialization ==========\n",
        "model_G = Generator().to(device)\n",
        "model_D = Discriminator().to(device)\n",
        "\n",
        "# ========== Loss & Optimizers ==========\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer_G = torch.optim.Adam(model_G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = torch.optim.Adam(model_D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# ========== Fixed Noise ==========\n",
        "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
        "\n",
        "# ========== Training Loop ==========\n",
        "k = 0\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_imgs, _) in enumerate(train_loader):\n",
        "        if i>0:\n",
        "            break\n",
        "        current_batch = real_imgs.size(0)\n",
        "        real_imgs = real_imgs.to(device)\n",
        "\n",
        "        # Real and fake labels\n",
        "        real_label = torch.full((current_batch, 1), 0.9, device=device)\n",
        "        fake_label = torch.zeros(current_batch, 1, device=device)\n",
        "\n",
        "        # ======== Train Discriminator ========\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_out = model_D(real_imgs)\n",
        "        real_loss = loss_fn(real_out, real_label)\n",
        "\n",
        "        noise = torch.randn(current_batch, latent_dim, 1, 1, device=device)\n",
        "        fake_imgs = model_G(noise)\n",
        "        fake_out = model_D(fake_imgs.detach())\n",
        "        fake_loss = loss_fn(fake_out, fake_label)\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ======== Train Generator ========\n",
        "        optimizer_G.zero_grad()\n",
        "        output = model_D(fake_imgs)\n",
        "        g_loss = loss_fn(output, real_label)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ======== Logging (optional but helpful) ========\n",
        "        if i % 100 == 0:\n",
        "            print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
        "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
        "\n",
        "        # ======== Save Sample Images ========\n",
        "        if i % 500 == 0:\n",
        "            with torch.no_grad():\n",
        "                fake_sample = model_G(fixed_noise).detach().cpu()\n",
        "                save_image(fake_sample, f\"dcgan_outputs/fake_{epoch:03d}_{k:04d}.png\", normalize=True)\n",
        "            k += 1\n",
        "\n",
        "# ========== Save Final Model ==========\n",
        "torch.save(model_G.state_dict(), \"dcgan_generator.pth\")\n",
        "torch.save(model_D.state_dict(), \"dcgan_discriminator.pth\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T19:59:10.03998Z",
          "iopub.execute_input": "2025-08-07T19:59:10.040308Z",
          "iopub.status.idle": "2025-08-07T19:59:13.981059Z",
          "shell.execute_reply.started": "2025-08-07T19:59:10.040285Z",
          "shell.execute_reply": "2025-08-07T19:59:13.979987Z"
        },
        "id": "RDD-bwryItGf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "zqdCsxP_ItGg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}