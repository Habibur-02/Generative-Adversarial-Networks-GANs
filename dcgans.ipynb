{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7587a05b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-06T17:55:30.068554Z",
     "iopub.status.busy": "2025-08-06T17:55:30.068249Z",
     "iopub.status.idle": "2025-08-06T17:55:32.148973Z",
     "shell.execute_reply": "2025-08-06T17:55:32.147842Z"
    },
    "papermill": {
     "duration": 2.087981,
     "end_time": "2025-08-06T17:55:32.151452",
     "exception": false,
     "start_time": "2025-08-06T17:55:30.063471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8faa2c",
   "metadata": {
    "papermill": {
     "duration": 0.002502,
     "end_time": "2025-08-06T17:55:32.157771",
     "exception": false,
     "start_time": "2025-08-06T17:55:32.155269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DCGAN= Deep Convolution GANs\n",
    "Upsampling convolution\n",
    "It is also called often.\n",
    "`Deconvolution or \n",
    "Fractionally strided convolution or\n",
    "Upconvolution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a95245",
   "metadata": {
    "papermill": {
     "duration": 0.002355,
     "end_time": "2025-08-06T17:55:32.162659",
     "exception": false,
     "start_time": "2025-08-06T17:55:32.160304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Output Size= (I-1)*S-2P+K\n",
    "I=Input size\n",
    "S=Stride\n",
    "P=Padding\n",
    "K=Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18944b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:55:32.169302Z",
     "iopub.status.busy": "2025-08-06T17:55:32.168821Z",
     "iopub.status.idle": "2025-08-06T17:55:37.396820Z",
     "shell.execute_reply": "2025-08-06T17:55:37.395667Z"
    },
    "papermill": {
     "duration": 5.233138,
     "end_time": "2025-08-06T17:55:37.398417",
     "exception": false,
     "start_time": "2025-08-06T17:55:32.165279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input=torch.randn(1,1,6,6)\n",
    "input\n",
    "\n",
    "model=nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1,\n",
    "             out_channels=10,\n",
    "             kernel_size=2,\n",
    "             padding=1,\n",
    "             stride=1,\n",
    "             bias=True),\n",
    "    nn.LeakyReLU(0.3),\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Tanh()\n",
    "    \n",
    ")\n",
    "\n",
    "output=model(input)\n",
    "output.shape\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6628e7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:55:37.405623Z",
     "iopub.status.busy": "2025-08-06T17:55:37.405132Z",
     "iopub.status.idle": "2025-08-06T17:55:37.457056Z",
     "shell.execute_reply": "2025-08-06T17:55:37.455676Z"
    },
    "papermill": {
     "duration": 0.057454,
     "end_time": "2025-08-06T17:55:37.458773",
     "exception": false,
     "start_time": "2025-08-06T17:55:37.401319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000, -0.6504, -0.0000, -0.5408, -0.1258, -0.6539,  0.9604],\n",
       "          [ 0.9874, -0.9042, -0.9640, -0.0000, -0.6443, -0.7513, -0.5277],\n",
       "          [ 0.0000, -0.0000, -0.9891, -0.0000, -0.2398, -0.0000,  0.8462],\n",
       "          [-0.3257, -0.9101, -0.7892,  0.8604, -0.0000, -0.3516,  0.0634],\n",
       "          [ 0.6609, -0.0000, -0.3346,  0.9805, -0.8764,  0.9658, -0.2578],\n",
       "          [ 0.7720, -0.4950, -0.7633, -0.0000,  0.9680,  0.9994, -0.0000],\n",
       "          [-0.3363, -0.0000,  0.8613,  0.9360,  0.6868,  0.6365,  0.0000]]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "input= torch.randn(1,3,8,8)\n",
    "input\n",
    "\n",
    "model=nn.Sequential(\n",
    "    nn.ConvTranspose2d(\n",
    "        in_channels=3,\n",
    "        out_channels=1,\n",
    "        kernel_size=2,\n",
    "             padding=1,\n",
    "             stride=1,\n",
    "             bias=True\n",
    "        \n",
    "    ),\n",
    "    nn.LeakyReLU(0.3),\n",
    "    nn.BatchNorm2d(1),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Tanh()\n",
    ")\n",
    "\n",
    "output=model(input)\n",
    "output.shape\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94998f07",
   "metadata": {
    "papermill": {
     "duration": 0.002382,
     "end_time": "2025-08-06T17:55:37.464104",
     "exception": false,
     "start_time": "2025-08-06T17:55:37.461722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# f(x)=x if x≥0\n",
    "#      αx if x<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6439005a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:55:37.471066Z",
     "iopub.status.busy": "2025-08-06T17:55:37.470739Z",
     "iopub.status.idle": "2025-08-06T17:55:58.954233Z",
     "shell.execute_reply": "2025-08-06T17:55:58.953017Z"
    },
    "papermill": {
     "duration": 21.489292,
     "end_time": "2025-08-06T17:55:58.956292",
     "exception": false,
     "start_time": "2025-08-06T17:55:37.467000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:11<00:00, 15.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "latent_dim = 100\n",
    "img_size = 32\n",
    "channels = 3\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "os.makedirs(\"dcgan_cifar10_output\", exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)  # Pixel: [-1, 1]\n",
    "])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR10(root=\"./data\", download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6257f439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:55:58.974483Z",
     "iopub.status.busy": "2025-08-06T17:55:58.974022Z",
     "iopub.status.idle": "2025-08-06T17:56:00.057340Z",
     "shell.execute_reply": "2025-08-06T17:56:00.056446Z"
    },
    "papermill": {
     "duration": 1.093802,
     "end_time": "2025-08-06T17:56:00.059125",
     "exception": false,
     "start_time": "2025-08-06T17:55:58.965323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "latent_dim = 100\n",
    "img_channels = 3\n",
    "img_size = 32\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(\"dcgan_outputs\", exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5bcfcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:56:00.077239Z",
     "iopub.status.busy": "2025-08-06T17:56:00.076903Z",
     "iopub.status.idle": "2025-08-06T17:56:00.137331Z",
     "shell.execute_reply": "2025-08-06T17:56:00.136366Z"
    },
    "papermill": {
     "duration": 0.07154,
     "end_time": "2025-08-06T17:56:00.138963",
     "exception": false,
     "start_time": "2025-08-06T17:56:00.067423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(512, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0), #in_chan,out_chan, kernel, stride, padd\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2,1), #in_chan,out_chan, kernel, stride, padd\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),       # (B,128,16,16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, img_channels, 4, 2, 1),# (B,3,32,32)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,z):\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model= nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 128, 4,2,1), #[B,128, 16, 16]\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128,256,4,2,1),   #8*8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),  #4*4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512,1,2,2,0),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "            \n",
    "        )\n",
    "    def forward(self, img):\n",
    "        out=self.model(img)\n",
    "        return out.view(-1,1).squeeze(1)\n",
    "        \n",
    "\n",
    "model_Gen= Generator().to(device)\n",
    "model_Gen\n",
    "\n",
    "model_Dis=Discriminator().to(device)\n",
    "\n",
    "model_Dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8a7845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:56:00.156447Z",
     "iopub.status.busy": "2025-08-06T17:56:00.156116Z",
     "iopub.status.idle": "2025-08-06T17:56:00.162409Z",
     "shell.execute_reply": "2025-08-06T17:56:00.161350Z"
    },
    "papermill": {
     "duration": 0.016377,
     "end_time": "2025-08-06T17:56:00.164032",
     "exception": false,
     "start_time": "2025-08-06T17:56:00.147655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn=nn.BCELoss()\n",
    "\n",
    "optimizer_G=torch.optim.Adam(params=model_Gen.parameters(),lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D=torch.optim.Adam(params=model_Dis.parameters(),lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "\n",
    "fixed_noise=torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.322542,
   "end_time": "2025-08-06T17:56:03.173840",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-06T17:55:24.851298",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
