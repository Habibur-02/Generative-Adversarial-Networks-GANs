{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad3b00b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:13.836742Z",
     "iopub.status.busy": "2025-08-07T09:44:13.835991Z",
     "iopub.status.idle": "2025-08-07T09:44:15.318169Z",
     "shell.execute_reply": "2025-08-07T09:44:15.317527Z"
    },
    "papermill": {
     "duration": 1.487453,
     "end_time": "2025-08-07T09:44:15.319566",
     "exception": false,
     "start_time": "2025-08-07T09:44:13.832113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693f1e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:15.325960Z",
     "iopub.status.busy": "2025-08-07T09:44:15.325369Z",
     "iopub.status.idle": "2025-08-07T09:44:24.089284Z",
     "shell.execute_reply": "2025-08-07T09:44:24.088619Z"
    },
    "papermill": {
     "duration": 8.768161,
     "end_time": "2025-08-07T09:44:24.090734",
     "exception": false,
     "start_time": "2025-08-07T09:44:15.322573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e05d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:24.096273Z",
     "iopub.status.busy": "2025-08-07T09:44:24.095953Z",
     "iopub.status.idle": "2025-08-07T09:44:27.893036Z",
     "shell.execute_reply": "2025-08-07T09:44:27.892192Z"
    },
    "papermill": {
     "duration": 3.801255,
     "end_time": "2025-08-07T09:44:27.894352",
     "exception": false,
     "start_time": "2025-08-07T09:44:24.093097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.97MB/s]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "img_size = 28 * 28\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "lr = 0.0002\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3cf46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:27.903256Z",
     "iopub.status.busy": "2025-08-07T09:44:27.902992Z",
     "iopub.status.idle": "2025-08-07T09:44:27.909512Z",
     "shell.execute_reply": "2025-08-07T09:44:27.908915Z"
    },
    "papermill": {
     "duration": 0.011838,
     "end_time": "2025-08-07T09:44:27.910512",
     "exception": false,
     "start_time": "2025-08-07T09:44:27.898674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(latent_dim,256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512,img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(img_size, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        return self.model(img.view(img.size(0), -1))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3f3ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:27.917136Z",
     "iopub.status.busy": "2025-08-07T09:44:27.916714Z",
     "iopub.status.idle": "2025-08-07T09:44:28.140702Z",
     "shell.execute_reply": "2025-08-07T09:44:28.139894Z"
    },
    "papermill": {
     "duration": 0.228736,
     "end_time": "2025-08-07T09:44:28.142191",
     "exception": false,
     "start_time": "2025-08-07T09:44:27.913455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_Gen=Generator().to(device)\n",
    "model_Dis=Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114a90a",
   "metadata": {
    "papermill": {
     "duration": 0.002762,
     "end_time": "2025-08-07T09:44:28.148077",
     "exception": false,
     "start_time": "2025-08-07T09:44:28.145315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss & Optimizer for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e700845e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:28.154840Z",
     "iopub.status.busy": "2025-08-07T09:44:28.154301Z",
     "iopub.status.idle": "2025-08-07T09:44:28.159601Z",
     "shell.execute_reply": "2025-08-07T09:44:28.158980Z"
    },
    "papermill": {
     "duration": 0.009987,
     "end_time": "2025-08-07T09:44:28.160762",
     "exception": false,
     "start_time": "2025-08-07T09:44:28.150775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d7748c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:28.167703Z",
     "iopub.status.busy": "2025-08-07T09:44:28.167194Z",
     "iopub.status.idle": "2025-08-07T09:44:28.171255Z",
     "shell.execute_reply": "2025-08-07T09:44:28.170733Z"
    },
    "papermill": {
     "duration": 0.008615,
     "end_time": "2025-08-07T09:44:28.172330",
     "exception": false,
     "start_time": "2025-08-07T09:44:28.163715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "optimizer_G=torch.optim.Adam(params=model_Gen.parameters(),lr=lr)\n",
    "optimizer_D=torch.optim.Adam(params=model_Dis.parameters(),lr=lr)\n",
    "\n",
    "loss_fn=nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc5cfeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:44:28.178939Z",
     "iopub.status.busy": "2025-08-07T09:44:28.178695Z",
     "iopub.status.idle": "2025-08-07T09:49:29.239897Z",
     "shell.execute_reply": "2025-08-07T09:49:29.239055Z"
    },
    "papermill": {
     "duration": 301.066063,
     "end_time": "2025-08-07T09:49:29.241379",
     "exception": false,
     "start_time": "2025-08-07T09:44:28.175316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0/938] [D loss: 1.4160501956939697] [G loss: 0.7777471542358398]\n",
      "[Batch 200/938] [D loss: 59.375] [G loss: 40.625]\n",
      "[Batch 400/938] [D loss: 79.6875] [G loss: 20.3125]\n",
      "[Batch 600/938] [D loss: 90.625] [G loss: 9.375]\n",
      "[Batch 800/938] [D loss: 98.4375] [G loss: 1.5625]\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for i,(img,_) in enumerate(train_loader):\n",
    "    real_img=img.to(device)\n",
    "    real_labels=torch.ones(img.size(0),1).to(device)\n",
    "    fake_labels=torch.zeros(img.size(0),1).to(device)\n",
    "    #Discriminator train\n",
    "    #Real img loss\n",
    "    optimizer_D.zero_grad()\n",
    "    real_output=model_Dis(real_img)\n",
    "    loss_disc_real=loss_fn(real_output, real_labels)\n",
    "    #Fake img create & loss\n",
    "\n",
    "    z=torch.randn(img.size(0),latent_dim).to(device)\n",
    "    fake_img=model_Gen(z)\n",
    "    #fake img loss\n",
    "    fake_output=model_Dis(fake_img.detach())\n",
    "    loss_disc_fake=loss_fn(fake_output,fake_labels)\n",
    "\n",
    "\n",
    "\n",
    "    #total loss \n",
    "    total_loss=loss_disc_real + loss_disc_fake\n",
    "    total_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #Generator train\n",
    "\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    validity=model_Dis(fake_img)\n",
    "    Gen_loss=loss_fn(validity,real_labels)\n",
    "    Gen_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f\"[Batch {i}/{len(train_loader)}] \"\n",
    "              f\"[D loss: {total_loss.item()}] [G loss: {Gen_loss.item()}]\")\n",
    "    #generate & save image\n",
    "    with torch.no_grad():\n",
    "        sample_z=torch.randn(16,latent_dim).to(device)\n",
    "        generated=model_Gen(sample_z).cpu()\n",
    "        plt.figure(figsize=(4,4))\n",
    "        for j in range(16):\n",
    "            plt.subplot(4, 4, j+1)\n",
    "            plt.imshow(generated[j].view(28, 28).numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.savefig(f\"gan_output_epoch.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54494dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T09:49:29.249484Z",
     "iopub.status.busy": "2025-08-07T09:49:29.249214Z",
     "iopub.status.idle": "2025-08-07T09:50:39.577926Z",
     "shell.execute_reply": "2025-08-07T09:50:39.577129Z"
    },
    "papermill": {
     "duration": 70.334418,
     "end_time": "2025-08-07T09:50:39.579414",
     "exception": false,
     "start_time": "2025-08-07T09:49:29.244996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] [Batch 0/938] [D loss: 1.4138] [G loss: 0.6861]\n",
      "[Epoch 1/5] [Batch 200/938] [D loss: 0.5197] [G loss: 1.8503]\n",
      "[Epoch 1/5] [Batch 400/938] [D loss: 0.6540] [G loss: 2.5600]\n",
      "[Epoch 1/5] [Batch 600/938] [D loss: 0.7472] [G loss: 2.9349]\n",
      "[Epoch 1/5] [Batch 800/938] [D loss: 0.4646] [G loss: 3.2542]\n",
      "[Epoch 2/5] [Batch 0/938] [D loss: 1.3427] [G loss: 1.2567]\n",
      "[Epoch 2/5] [Batch 200/938] [D loss: 1.2465] [G loss: 1.5435]\n",
      "[Epoch 2/5] [Batch 400/938] [D loss: 0.5029] [G loss: 3.2766]\n",
      "[Epoch 2/5] [Batch 600/938] [D loss: 1.1806] [G loss: 2.2818]\n",
      "[Epoch 2/5] [Batch 800/938] [D loss: 0.5852] [G loss: 2.2243]\n",
      "[Epoch 3/5] [Batch 0/938] [D loss: 1.2744] [G loss: 1.4221]\n",
      "[Epoch 3/5] [Batch 200/938] [D loss: 1.9331] [G loss: 0.8820]\n",
      "[Epoch 3/5] [Batch 400/938] [D loss: 0.5408] [G loss: 2.2207]\n",
      "[Epoch 3/5] [Batch 600/938] [D loss: 1.2022] [G loss: 1.1568]\n",
      "[Epoch 3/5] [Batch 800/938] [D loss: 1.0409] [G loss: 1.8425]\n",
      "[Epoch 4/5] [Batch 0/938] [D loss: 0.9141] [G loss: 1.9793]\n",
      "[Epoch 4/5] [Batch 200/938] [D loss: 1.1175] [G loss: 2.4188]\n",
      "[Epoch 4/5] [Batch 400/938] [D loss: 0.5820] [G loss: 2.7235]\n",
      "[Epoch 4/5] [Batch 600/938] [D loss: 0.6620] [G loss: 2.5773]\n",
      "[Epoch 4/5] [Batch 800/938] [D loss: 1.1623] [G loss: 1.4036]\n",
      "[Epoch 5/5] [Batch 0/938] [D loss: 1.0894] [G loss: 1.2782]\n",
      "[Epoch 5/5] [Batch 200/938] [D loss: 0.7046] [G loss: 2.0366]\n",
      "[Epoch 5/5] [Batch 400/938] [D loss: 0.9987] [G loss: 1.3146]\n",
      "[Epoch 5/5] [Batch 600/938] [D loss: 0.8161] [G loss: 2.2355]\n",
      "[Epoch 5/5] [Batch 800/938] [D loss: 0.9070] [G loss: 1.3973]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# ========== Hyperparameters ==========\n",
    "latent_dim = 100\n",
    "img_size = 28 * 28\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== DataLoader ==========\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Range: [-1, 1]\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ========== Generator ==========\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# ========== Discriminator ==========\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        return self.model(img_flat)\n",
    "\n",
    "# ========== Initialize Models ==========\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "# ========== Training ==========\n",
    "os.makedirs(\"gan_outputs\", exist_ok=True)\n",
    "fixed_noise = torch.randn(16, latent_dim).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        batch_size_i = imgs.size(0)\n",
    "\n",
    "        # Flatten and send to device\n",
    "        real_imgs = imgs.view(batch_size_i, -1).to(device)\n",
    "\n",
    "        # Labels with smoothing\n",
    "        real_labels = torch.full((batch_size_i, 1), 0.9, device=device)\n",
    "        fake_labels = torch.zeros(batch_size_i, 1).to(device)\n",
    "\n",
    "        # ======== Train Discriminator ========\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_output = D(real_imgs)\n",
    "        loss_real = loss_fn(real_output, real_labels)\n",
    "\n",
    "        z = torch.randn(batch_size_i, latent_dim).to(device)\n",
    "        fake_imgs = G(z)\n",
    "        fake_output = D(fake_imgs.detach())\n",
    "        loss_fake = loss_fn(fake_output, fake_labels)\n",
    "\n",
    "        d_loss = loss_real + loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ======== Train Generator ========\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        validity = D(fake_imgs)\n",
    "        g_loss = loss_fn(validity, real_labels)  # Want D to think G's images are real\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ======== Logs ========\n",
    "        if i % 200 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
    "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "    # ======== Save Sample Images ========\n",
    "    with torch.no_grad():\n",
    "        generated = G(fixed_noise).view(-1, 1, 28, 28)\n",
    "        save_image(generated, f\"gan_outputs/sample_epoch_{epoch+1}.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14918de2",
   "metadata": {
    "papermill": {
     "duration": 0.004178,
     "end_time": "2025-08-07T09:50:39.588974",
     "exception": false,
     "start_time": "2025-08-07T09:50:39.584796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 393.136493,
   "end_time": "2025-08-07T09:50:42.812795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-07T09:44:09.676302",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
